# ğŸš€ MLOps Workshop - Production ML Pipeline

A complete, production-grade MLOps environment for teaching real-world machine learning operations. This workshop demonstrates an end-to-end ML pipeline with Customer Churn Prediction using industry-standard tools.

![Architecture](docs/architecture.png)

## ğŸ“‹ Table of Contents

- [Overview](#overview)
- [Architecture](#architecture)
- [Prerequisites](#prerequisites)
- [Quick Start](#quick-start)
- [Project Structure](#project-structure)
- [Components](#components)
- [ML Pipeline](#ml-pipeline)
- [Access URLs](#access-urls)
- [Workshop Guide](#workshop-guide)
- [Troubleshooting](#troubleshooting)

## ğŸ¯ Overview

This workshop provides a hands-on experience with:

| Component | Technology | Purpose |
|-----------|------------|---------|
| **Container Orchestration** | Kubernetes (Kind) | 3-node cluster for production-like environment |
| **Workflow Orchestration** | Apache Airflow | DAG-based ML pipeline automation |
| **Experiment Tracking** | MLflow | Model versioning, metrics, and registry |
| **Object Storage** | MinIO | S3-compatible data lake and artifact storage |
| **Database** | PostgreSQL | Backend for MLflow and Airflow |
| **Feature Store** | Redis | Online feature serving cache |
| **Model Serving** | FastAPI | REST API with A/B testing |
| **Frontend** | React + TailwindCSS | Real-time prediction dashboard |

### ğŸ“ Use Case: Telco Customer Churn Prediction

We use the **IBM Telco Customer Churn** dataset (verified, real-world data) to demonstrate:
- Data ingestion from external sources
- Feature engineering pipeline
- Multi-model training (Logistic Regression, Random Forest, Gradient Boosting)
- A/B testing between model versions
- Real-time prediction serving

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        KIND KUBERNETES CLUSTER                               â”‚
â”‚                     (1 Control Plane + 2 Workers)                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚  â”‚   AIRFLOW    â”‚â”€â”€â”€â–¶â”‚    MINIO     â”‚â—€â”€â”€â”€â”‚   MLFLOW     â”‚                   â”‚
â”‚  â”‚  Scheduler   â”‚    â”‚  Data Lake   â”‚    â”‚  Tracking    â”‚                   â”‚
â”‚  â”‚  Webserver   â”‚    â”‚  Artifacts   â”‚    â”‚  Registry    â”‚                   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚         â”‚                   â”‚                   â”‚                            â”‚
â”‚         â”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚                            â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚  POSTGRESQL  â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                            â”‚
â”‚                      â”‚   Backend    â”‚                                        â”‚
â”‚                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                        â”‚
â”‚                             â”‚                                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚  â”‚                  MODEL SERVING LAYER                  â”‚                   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚                   â”‚
â”‚  â”‚  â”‚   FastAPI   â”‚    â”‚  A/B Router â”‚    â”‚  Redis   â”‚  â”‚                   â”‚
â”‚  â”‚  â”‚   /predict  â”‚â—€â”€â”€â–¶â”‚  80%/20%    â”‚â—€â”€â”€â–¶â”‚  Cache   â”‚  â”‚                   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚                   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚                             â”‚                                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚  â”‚              FRONTEND DASHBOARD (React)               â”‚                   â”‚
â”‚  â”‚  â€¢ Real-time Predictions  â€¢ A/B Test Visualization   â”‚                   â”‚
â”‚  â”‚  â€¢ Model Comparison       â€¢ Feature Importance       â”‚                   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“¦ Prerequisites

Before starting, ensure you have:

- **Docker Desktop** - [Download](https://www.docker.com/products/docker-desktop)
- **kubectl** - [Install Guide](https://kubernetes.io/docs/tasks/tools/)
- **Kind** - [Install Guide](https://kind.sigs.k8s.io/docs/user/quick-start/#installation)
- **Python 3.10+** - [Download](https://www.python.org/downloads/)
- **Node.js 18+** (for frontend development) - [Download](https://nodejs.org/)

### Windows Installation

```powershell
# Install Kind (using Chocolatey)
choco install kind -y

# Install kubectl
choco install kubernetes-cli -y

# Verify installations
kind version
kubectl version --client
docker version
```

## ğŸš€ Quick Start

### Step 1: Clone and Setup

```powershell
cd F:\MLOPS-Fundamentals\mlops-lab-workshop
```

### Step 2: Deploy Everything

```powershell
# Option A: Deploy all at once
.\scripts\deploy-all.ps1

# Option B: Step-by-step deployment
.\scripts\01-create-cluster.ps1       # Create Kind cluster
.\scripts\02-deploy-infrastructure.ps1 # Deploy MinIO, PostgreSQL
.\scripts\03-deploy-mlflow.ps1         # Deploy MLflow
.\scripts\04-deploy-airflow.ps1        # Deploy Airflow
.\scripts\05-deploy-ml-pipeline.ps1    # Deploy ML serving components
```

### Step 3: Access Services

```powershell
# Start all port-forwards
.\scripts\port-forward.ps1
```

### Step 4: Run ML Pipeline

```powershell
# Run the complete ML pipeline
.\scripts\06-run-ml-pipeline.ps1
```

## ğŸ“ Project Structure

```
mlops-lab-workshop/
â”œâ”€â”€ ğŸ“ k8s/                          # Kubernetes manifests
â”‚   â”œâ”€â”€ airflow/                     # Airflow deployment
â”‚   â”œâ”€â”€ mlflow/                      # MLflow deployment
â”‚   â”œâ”€â”€ minio/                       # MinIO (S3) deployment
â”‚   â”œâ”€â”€ postgres/                    # PostgreSQL deployment
â”‚   â”œâ”€â”€ redis/                       # Redis deployment
â”‚   â”œâ”€â”€ model-serving/               # FastAPI model serving
â”‚   â”œâ”€â”€ frontend/                    # React dashboard
â”‚   â””â”€â”€ namespaces/                  # Namespace definitions
â”‚
â”œâ”€â”€ ğŸ“ src/                          # Source code
â”‚   â”œâ”€â”€ data/                        # Data ingestion scripts
â”‚   â”‚   â””â”€â”€ download_data.py
â”‚   â”œâ”€â”€ features/                    # Feature engineering
â”‚   â”‚   â””â”€â”€ feature_engineering.py
â”‚   â”œâ”€â”€ training/                    # Model training
â”‚   â”‚   â””â”€â”€ train_model.py
â”‚   â”œâ”€â”€ serving/                     # FastAPI application
â”‚   â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”‚   â”œâ”€â”€ main.py             # API endpoints
â”‚   â”‚   â”‚   â”œâ”€â”€ predictor.py        # Model inference
â”‚   â”‚   â”‚   â””â”€â”€ ab_router.py        # A/B testing logic
â”‚   â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”‚   â””â”€â”€ requirements.txt
â”‚   â””â”€â”€ frontend/                    # React dashboard
â”‚       â”œâ”€â”€ src/
â”‚       â”œâ”€â”€ package.json
â”‚       â””â”€â”€ Dockerfile
â”‚
â”œâ”€â”€ ğŸ“ dags/                         # Airflow DAGs
â”‚   â”œâ”€â”€ 01_data_ingestion.py        # Download & store data
â”‚   â”œâ”€â”€ 02_feature_engineering.py   # Transform features
â”‚   â”œâ”€â”€ 03_model_training.py        # Train & register models
â”‚   â”œâ”€â”€ 04_model_evaluation.py      # Evaluate & update A/B
â”‚   â””â”€â”€ 05_full_pipeline.py         # End-to-end orchestration
â”‚
â”œâ”€â”€ ğŸ“ scripts/                      # Deployment scripts
â”‚   â”œâ”€â”€ deploy-all.ps1              # One-click deployment
â”‚   â”œâ”€â”€ 01-create-cluster.ps1
â”‚   â”œâ”€â”€ 02-deploy-infrastructure.ps1
â”‚   â”œâ”€â”€ 03-deploy-mlflow.ps1
â”‚   â”œâ”€â”€ 04-deploy-airflow.ps1
â”‚   â”œâ”€â”€ 05-deploy-ml-pipeline.ps1
â”‚   â”œâ”€â”€ 06-run-ml-pipeline.ps1
â”‚   â”œâ”€â”€ port-forward.ps1            # Access all services
â”‚   â”œâ”€â”€ status.ps1                  # Check cluster status
â”‚   â””â”€â”€ cleanup.ps1                 # Remove everything
â”‚
â”œâ”€â”€ ğŸ“ github-dags-template/         # Template for GitHub DAGs repo
â”œâ”€â”€ kind-cluster-config.yaml         # Kind cluster configuration
â”œâ”€â”€ requirements.txt                 # Python dependencies
â””â”€â”€ README.md                        # This file
```

## ğŸ”§ Components

### 1. Data Layer (MinIO)

MinIO provides S3-compatible storage for:
- **Raw Data**: `data-lake/raw/telco_churn/`
- **Processed Features**: `data-lake/processed/features/`
- **Model Artifacts**: `mlflow-artifacts/`

### 2. Feature Engineering

Transforms raw customer data into ML features:

| Feature Category | Examples |
|-----------------|----------|
| **Tenure** | `tenure_months`, `is_new_customer`, `is_loyal_customer` |
| **Charges** | `monthly_charges`, `avg_monthly_charge`, `charge_per_tenure` |
| **Services** | `total_services`, `has_internet`, `has_streaming` |
| **Contract** | `contract_month_to_month`, `payment_electronic` |
| **Risk** | `risk_score` (calculated heuristic) |

### 3. Model Training

Three models trained and compared:

| Model | Description | Typical AUC |
|-------|-------------|-------------|
| Logistic Regression | Baseline, interpretable | ~0.82 |
| Random Forest | Ensemble, good accuracy | ~0.85 |
| Gradient Boosting | Best performance | ~0.86 |

### 4. A/B Testing

- **Champion Model**: 80% traffic (best performer)
- **Challenger Model**: 20% traffic (experimental)
- Real-time metrics tracking
- Automatic promotion based on performance

### 5. Model Serving API

FastAPI endpoints:

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/predict` | POST | Single customer prediction |
| `/predict/batch` | POST | Batch predictions |
| `/predict/explain` | POST | Prediction with feature importance |
| `/models` | GET | List deployed models |
| `/ab-stats` | GET | A/B testing statistics |
| `/health` | GET | Health check |
| `/metrics` | GET | Prometheus metrics |

### 6. Frontend Dashboard

React-based dashboard with:
- Real-time churn predictions
- Model performance comparison
- A/B test visualization
- Feature importance charts

## ğŸ”„ ML Pipeline

### Airflow DAGs

| DAG | Schedule | Description |
|-----|----------|-------------|
| `01_data_ingestion` | Daily | Download dataset from IBM, upload to MinIO |
| `02_feature_engineering` | Daily | Transform raw data to features |
| `03_model_training` | Weekly | Train models, register in MLflow |
| `04_model_evaluation` | Daily | Compare models, update A/B config |
| `05_full_pipeline` | Weekly | End-to-end orchestration |

### Running the Pipeline

**Option 1: Via Airflow UI**
1. Open http://localhost:8080
2. Enable the `05_full_pipeline` DAG
3. Trigger manually or wait for schedule

**Option 2: Via Script**
```powershell
.\scripts\06-run-ml-pipeline.ps1
```

## ğŸŒ Access URLs

After running `.\scripts\port-forward.ps1`:

| Service | URL | Credentials |
|---------|-----|-------------|
| **Airflow UI** | http://localhost:8080 | `admin` / `admin123` |
| **MLflow UI** | http://localhost:5000 | (no auth) |
| **MinIO Console** | http://localhost:9001 | `minioadmin` / `minioadmin123` |
| **Model API Docs** | http://localhost:8000/docs | (no auth) |
| **Dashboard** | http://localhost:3000 | (no auth) |

## ğŸ“š Workshop Guide

### Module 1: Infrastructure Setup (30 min)
1. Create Kind cluster
2. Deploy MinIO and PostgreSQL
3. Explore Kubernetes resources

### Module 2: MLflow & Experiment Tracking (30 min)
1. Deploy MLflow
2. Run training script
3. Compare experiments in UI
4. Understand model registry

### Module 3: Data Pipeline (45 min)
1. Explore data ingestion DAG
2. Run feature engineering
3. Understand feature store concepts

### Module 4: Model Training & Registry (45 min)
1. Train multiple models
2. Compare metrics
3. Promote to production
4. Version management

### Module 5: Model Serving & A/B Testing (45 min)
1. Deploy FastAPI service
2. Make predictions
3. Understand A/B routing
4. Monitor performance

### Module 6: Frontend & Integration (30 min)
1. Explore dashboard
2. End-to-end prediction flow
3. Real-world scenarios

## ğŸ” Troubleshooting

### Common Issues

**Pods not starting?**
```powershell
kubectl get pods -A
kubectl describe pod <pod-name> -n <namespace>
kubectl logs <pod-name> -n <namespace>
```

**MLflow not connecting to MinIO?**
```powershell
# Check MinIO is accessible
kubectl port-forward svc/minio 9000:9000 -n minio
# Test with aws cli
aws --endpoint-url http://localhost:9000 s3 ls
```

**Airflow DAGs not showing?**
```powershell
# Check DAG sync
kubectl logs deployment/airflow-scheduler -n airflow
```

**Model serving failing?**
```powershell
# Check if models are registered
kubectl port-forward svc/mlflow 5000:5000 -n mlflow
# Visit http://localhost:5000/#/models
```

### Reset Everything

```powershell
.\scripts\cleanup.ps1
.\scripts\deploy-all.ps1
```

## ğŸ“Š Dataset Information

**Telco Customer Churn Dataset**
- **Source**: IBM Watson Analytics Sample Data
- **Size**: 7,043 customers
- **Features**: 21 columns
- **Target**: Churn (Yes/No)
- **Churn Rate**: ~26.5%

## ğŸ¤ Contributing

This is an educational project. Feel free to:
- Add new models
- Improve feature engineering
- Enhance the dashboard
- Add monitoring with Prometheus/Grafana

## ğŸ“„ License

MIT License - Use freely for educational purposes.

---

**Happy Learning! ğŸ“**

*Built for MLOps/AIOps Workshop - production ML to experienced professionals*
