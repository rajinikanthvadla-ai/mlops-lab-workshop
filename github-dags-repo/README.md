# ğŸš€ MLOps Workshop - Airflow DAGs Repository

This repository contains Airflow DAGs for the MLOps Workshop's Customer Churn Prediction pipeline.

## ğŸ“‹ DAGs Overview

| DAG | Schedule | Description |
|-----|----------|-------------|
| `01_data_ingestion` | Daily | Downloads IBM Telco Churn dataset, validates, uploads to MinIO |
| `02_feature_engineering` | Daily | Transforms raw data into 24 ML features |
| `03_model_training` | Weekly | Trains 3 models (LR, RF, GB), registers best in MLflow |
| `04_model_evaluation` | Daily | Compares models, updates A/B testing config |
| `05_full_pipeline` | Weekly | End-to-end orchestration of all DAGs |

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    AIRFLOW DAGs                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  01_data_ingestion â”€â”€â–º 02_feature_engineering â”€â”€â–º           â”‚
â”‚                                                              â”‚
â”‚  03_model_training â”€â”€â–º 04_model_evaluation                  â”‚
â”‚                                                              â”‚
â”‚  05_full_pipeline (orchestrates all above)                  â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                    â”‚                    â”‚
         â–¼                    â–¼                    â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  MinIO  â”‚         â”‚ MLflow  â”‚         â”‚ Postgres â”‚
    â”‚(Storage)â”‚         â”‚(Tracking)â”‚        â”‚(Backend) â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Repository Structure

```
mlops-workshop-dags/
â”œâ”€â”€ dags/
â”‚   â”œâ”€â”€ 01_data_ingestion.py      # Data download & upload
â”‚   â”œâ”€â”€ 02_feature_engineering.py  # Feature transformation
â”‚   â”œâ”€â”€ 03_model_training.py       # Model training & registry
â”‚   â”œâ”€â”€ 04_model_evaluation.py     # Model comparison & A/B config
â”‚   â””â”€â”€ 05_full_pipeline.py        # End-to-end orchestration
â””â”€â”€ README.md
```

## ğŸ”§ Configuration

### Environment Variables

The DAGs expect these environment variables (set in Airflow):

| Variable | Default | Description |
|----------|---------|-------------|
| `MINIO_ENDPOINT` | `http://minio.minio.svc.cluster.local:9000` | MinIO service URL |
| `MINIO_ACCESS_KEY` | `minioadmin` | MinIO access key |
| `MINIO_SECRET_KEY` | `minioadmin123` | MinIO secret key |
| `MLFLOW_TRACKING_URI` | `http://mlflow.mlflow.svc.cluster.local:5000` | MLflow tracking URL |

### Required Python Packages

The Airflow workers need these packages:

```
pandas
numpy
scikit-learn
mlflow
boto3
pyarrow
```

## ğŸš€ Usage

### Manual Trigger

1. Open Airflow UI (http://localhost:8080)
2. Enable the desired DAG
3. Click "Trigger DAG" button

### Automatic Execution

DAGs run on their configured schedules:
- **Daily DAGs**: Run once per day
- **Weekly DAGs**: Run once per week

### Full Pipeline

To run the complete ML pipeline:
1. Enable `05_full_pipeline`
2. It will trigger all other DAGs in sequence

## ğŸ“Š Data Flow

```
IBM GitHub â”€â”€â–º MinIO (raw/) â”€â”€â–º Feature Engineering â”€â”€â–º MinIO (processed/)
                                       â”‚
                                       â–¼
                               Model Training
                                       â”‚
                                       â–¼
                            MLflow Model Registry
                                       â”‚
                                       â–¼
                            A/B Config Update
```

## ğŸ” Monitoring

### Check DAG Status
```bash
kubectl logs deployment/airflow-scheduler -n airflow
```

### Check Git-Sync Status
```bash
kubectl logs deployment/airflow-scheduler -n airflow -c git-sync
```

### View in Airflow UI
- DAG runs: http://localhost:8080/home
- Task logs: Click on task in Grid/Graph view

## ğŸ“ Adding New DAGs

1. Create a new `.py` file in the `dags/` folder
2. Follow the existing DAG structure
3. Commit and push to GitHub
4. DAG will auto-sync within 60 seconds

## ğŸ› Troubleshooting

### DAGs not appearing?
```bash
# Check git-sync logs
kubectl logs deployment/airflow-scheduler -n airflow -c git-sync

# Check for Python syntax errors
kubectl logs deployment/airflow-scheduler -n airflow -c scheduler
```

### Task failures?
1. Check task logs in Airflow UI
2. Verify MinIO/MLflow connectivity
3. Check required Python packages are installed

---

**Part of MLOps Workshop** | Built for teaching production ML operations

